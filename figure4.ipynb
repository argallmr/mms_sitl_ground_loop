{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMS SITL Ground Loop: Model Performance Measures\n",
    "This notebook reproduces Figure 4 of Argall, Small, et al. 2020.\n",
    "\n",
    "**CONTENTS**\n",
    "* [Front Matter](#front_matter)\n",
    "* [Configurable Parameters](#inputs)\n",
    "* [Metric Calculations](#metric)\n",
    "* [Burst Selections](#selections)\n",
    "* [Histogram Overlap](#histogram)\n",
    "* [Venn Diagram](#venn_diagram)\n",
    "* [Confusion Matrix, Precision, Recall, F1 Score](#f1_score)\n",
    "* [Confusion Matrix Plot](#confusion_matrix)\n",
    "\n",
    "<a id='front_matter'></a>\n",
    "## Front matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import datetime as dt\n",
    "import pymms\n",
    "from pymms.sdc import selections as sel\n",
    "from pymms.sdc import mrmms_sdc_api as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inputs'></a>\n",
    "## Configurable Parameters\n",
    "The figure plots data from SROI 1 only between 19 Oct. 2019, which is when the GLS was fully implemented, and 25 Mar. 2020, a few days before the paper was submitted. To reproduce the plots in the supplemental material, set `sroi=None` and `sroi=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sroi = 1\n",
    "outdir = pymms.config['gls_root'] + '/gls_paper' # Set to None to suppress output\n",
    "fig_type = 'svg' # eps, pdf, pgf, png, ps, raw, rgba, svg, svgz\n",
    "start_date = dt.datetime(2019, 10, 19)\n",
    "end_date = dt.datetime(2020, 3, 25, 18, 44, 46)\n",
    "\n",
    "# Filter selections to be within a particular SROI\n",
    "do_sroi=0\n",
    "if sroi in (1, 2, 3):\n",
    "    do_sroi=True\n",
    "\n",
    "# Location to save the figure\n",
    "if outdir is not None:\n",
    "    outdir = pathlib.Path(outdir).expanduser()\n",
    "    if not outdir.exists():\n",
    "        outdir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='metric'></a>\n",
    "## Metric Calculations\n",
    "A function to calculate and histogram the overlap between selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(ref_data, test_data, fig, labels, location,\n",
    "                nbins=10):\n",
    "    '''\n",
    "    Visualize the overlap between segments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ref_data : list of `BurstSegment`s\n",
    "        Reference burst segments\n",
    "    test_data : list of `BurstSegment`s\n",
    "        Test burst segments. Determine which test segments\n",
    "        overlap with the reference segments and by how much\n",
    "    labels : tuple of str\n",
    "        Labels for the reference and test segments\n",
    "    location : tuple\n",
    "        Location of the figure (row, col, nrows, ncols)\n",
    "    nbins : int\n",
    "        Number of histogram bins to create\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ax : `matplotlib.pyplot.Axes`\n",
    "        Axes in which data is displayed\n",
    "    ref_test_data : list of `BurstSegment`s\n",
    "        Reference data that falls within the [start, stop] times\n",
    "        of the test data.\n",
    "    '''\n",
    "\n",
    "    # Determine by how much the test data overlaps with\n",
    "    # the reference data.\n",
    "    ref_test = []\n",
    "    ref_test_data = []\n",
    "    ref_test = [selection_overlap(segment, test_data)\n",
    "                for segment in ref_data]\n",
    "\n",
    "    # Overlap statistics\n",
    "    #   - Number of segments selected\n",
    "    #   - Percentage of segments selected\n",
    "    #   - Percent overlap from each segment\n",
    "    ref_test_selected = sum(selection['n_selections'] > 0\n",
    "                            for selection in ref_test)\n",
    "    ref_test_pct_selected = ref_test_selected / len(ref_test) * 100.0\n",
    "    ref_test_pct_overlap = [selection['pct_overlap'] for selection in ref_test]\n",
    "\n",
    "    # Calculate the plot index from the (row,col) subplot location\n",
    "    plot_idx = lambda rowcol, ncols : (rowcol[0]-1)*ncols + rowcol[1]\n",
    "\n",
    "    # Create a figure\n",
    "    ax = fig.add_subplot(location[2], location[3],\n",
    "                         plot_idx(location[0:2], location[3]))\n",
    "    hh = ax.hist(ref_test_pct_overlap, bins=nbins, range=(0, 100))\n",
    "    #ax.set_xlabel('% Overlap Between {0} and {1} Segments'.format(*labels))\n",
    "    if location[0] == location[2]:\n",
    "        ax.set_xlabel('% Overlap per Segment')\n",
    "    if location[1] == 1:\n",
    "        ax.set_ylabel('Occurrence')\n",
    "    ax.text(0.5, 0.98, '{0:4.1f}% of {1:d}'\n",
    "              .format(ref_test_pct_selected, len(ref_test)),\n",
    "              verticalalignment='top', horizontalalignment='center',\n",
    "              transform=ax.transAxes)\n",
    "    ax.set_title('{0} Segments\\nSelected by {1}'.format(*labels))\n",
    "\n",
    "    return ax, ref_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how much overlap one burst segment of a given class has with another class of burst segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_overlap(ref, tests):\n",
    "    '''\n",
    "    Gather overlap statistics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ref : `selections.BurstSegment`\n",
    "        The reference burst segment.\n",
    "    tests : list of `selections.BurstSegment`\n",
    "        The burst segements against which the reference segment is compared.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : dict\n",
    "        Data regarding how much the reference segment overlaps with the\n",
    "        test segments.\n",
    "    '''\n",
    "    out = {'dt': ref.tstop - ref.tstart,\n",
    "           'dt_next': dt.timedelta(days=7000),\n",
    "           'n_selections': 0,\n",
    "           't_overlap': dt.timedelta(seconds=0.0),\n",
    "           't_overselect': dt.timedelta(seconds=0.0),\n",
    "           'pct_overlap': 0.0,\n",
    "           'pct_overselect': 0.0\n",
    "           }\n",
    "\n",
    "    # Find which selections overlap with the given entry and by how much\n",
    "    tdelta = dt.timedelta(days=7000)\n",
    "    for test in tests:\n",
    "\n",
    "        if ((test.tstart <= ref.tstop) and\n",
    "            (test.tstop >= ref.tstart)\n",
    "            ):\n",
    "            out['n_selections'] += 1\n",
    "            out['t_overlap'] += (min(test.tstop, ref.tstop)\n",
    "                                 - max(test.tstart, ref.tstart)\n",
    "                                 )\n",
    "\n",
    "        # Time to nearest interval\n",
    "        out['dt_next'] = min(out['dt_next'], abs(test.tstart - ref.tstart))\n",
    "\n",
    "    # Overlap and over-selection statistics\n",
    "    if out['n_selections'] > 0:\n",
    "        out['t_overselect'] = out['dt'] - out['t_overlap']\n",
    "        out['pct_overlap'] = out['t_overlap'] / out['dt'] * 100.0\n",
    "        out['pct_overselect'] = out['t_overselect'] / out['dt'] * 100.0\n",
    "    else:\n",
    "        out['t_overselect'] = out['dt']\n",
    "        out['pct_overselect'] = 100.0\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='selections'></a>\n",
    "## Burst Selections\n",
    "Get the SITL, ABS, and GLS burst selections. Filter by SROI and determine which SITL selections were classified as magnetopause crossings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_data = sel.selections('abs', start_date, end_date,\n",
    "                          latest=True, combine=True, metadata=do_sroi)\n",
    "\n",
    "gls_data = sel.selections('mp-dl-unh', start_date, end_date,\n",
    "                          latest=True, combine=True, metadata=do_sroi)\n",
    "\n",
    "sitl_data = sel.selections('sitl+back', start_date, end_date,\n",
    "                           latest=True, combine=True, metadata=do_sroi)\n",
    "\n",
    "# Filter by SROI\n",
    "if do_sroi:\n",
    "    abs_data = [s for s in abs_data if s.sroi == sroi]\n",
    "    sitl_data = [s for s in sitl_data if s.sroi == sroi]\n",
    "    gls_data = [s for s in gls_data if s.sroi == sroi]\n",
    "\n",
    "sitl_mp_data = sel.filter_segments(sitl_data, '(MP|Magnetopause|magnetopause)', case_sensitive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the selections for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if outdir is not None:\n",
    "    sroi_str = ''\n",
    "    if do_sroi:\n",
    "        sroi_str = '_sroi{0:d}'.format(sroi)\n",
    "    \n",
    "    for stype, data in zip(('sitl', 'abs', 'gls'), (sitl_data, abs_data, gls_data)):\n",
    "        csv_fname = (outdir\n",
    "                     / '_'.join((stype + '_selections' + sroi_str,\n",
    "                                 start_date.strftime('%Y%m%d%H%M%S'),\n",
    "                                 end_date.strftime('%Y%m%d%H%M%S')\n",
    "                                 )))\n",
    "        csv_fname = csv_fname.with_suffix('.csv')\n",
    "        sel.write_csv(csv_fname, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='histogram'></a>\n",
    "## Histogram Overlap\n",
    "Here, we create the figure. `plot_metric` will determine the overlap between each class of selections, plot a histogram of the results, and annotate the figure with summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "nbins = 10\n",
    "nrows = 4\n",
    "ncols = 3\n",
    "fig = plt.figure(figsize=(8.5, 10))\n",
    "fig.subplots_adjust(hspace=0.55, wspace=0.3)\n",
    "\n",
    "# GLS-SITL Comparison\n",
    "ax, gls_sitl = plot_metric(gls_data, sitl_data, fig,\n",
    "                           ('GLS', 'SITL'), (1, 1, nrows, ncols),\n",
    "                           nbins=nbins)\n",
    "ax, sitl_gls = plot_metric(sitl_data, gls_data, fig,\n",
    "                           ('SITL', 'GLS'), (2, 1, nrows, ncols),\n",
    "                           nbins=nbins)\n",
    "ax, gls_sitl_mp = plot_metric(gls_data, sitl_mp_data, fig,\n",
    "                              ('GLS', 'SITL MP'), (3, 1, nrows, ncols),\n",
    "                              nbins=nbins)\n",
    "ax, sitl_mp_gls = plot_metric(sitl_mp_data, gls_data, fig,\n",
    "                              ('SITL MP', 'GLS'), (4, 1, nrows, ncols),\n",
    "                              nbins=nbins)\n",
    "\n",
    "# ABS-SITL Comparison\n",
    "ax, abs_sitl = plot_metric(abs_data, sitl_data, fig,\n",
    "                           ('ABS', 'SITL'), (1, 2, nrows, ncols),\n",
    "                           nbins=nbins)\n",
    "ax, sitl_abs = plot_metric(sitl_data, abs_data, fig,\n",
    "                           ('SITL', 'ABS'), (2, 2, nrows, ncols),\n",
    "                           nbins=nbins)\n",
    "ax, abs_sitl_mp = plot_metric(abs_data, sitl_mp_data, fig,\n",
    "                              ('ABS', 'SITL MP'), (3, 2, nrows, ncols),\n",
    "                              nbins=nbins)\n",
    "ax, sitl_mp_abs = plot_metric(sitl_mp_data, abs_data, fig,\n",
    "                              ('SITL MP', 'ABS'), (4, 2, nrows, ncols),\n",
    "                              nbins=nbins)\n",
    "\n",
    "# GLS-ABS Comparison\n",
    "abs_mp_data = [abs_data[idx]\n",
    "               for idx, s in enumerate(abs_sitl_mp)\n",
    "               if s['n_selections'] > 0]\n",
    "\n",
    "ax, gls_abs = plot_metric(gls_data, abs_data, fig,\n",
    "                          ('GLS', 'ABS'), (1, 3, nrows, ncols),\n",
    "                          nbins=nbins)\n",
    "ax, abs_gls = plot_metric(abs_data, gls_data, fig,\n",
    "                          ('ABS', 'GLS'), (2, 3, nrows, ncols),\n",
    "                          nbins=nbins)\n",
    "ax, gls_abs_mp = plot_metric(gls_data, abs_mp_data, fig,\n",
    "                             ('GLS', 'ABS MP'), (3, 3, nrows, ncols),\n",
    "                             nbins=nbins)\n",
    "ax, abs_mp_gls = plot_metric(abs_mp_data, gls_data, fig,\n",
    "                             ('ABS MP', 'GLS'), (4, 3, nrows, ncols),\n",
    "                             nbins=nbins)\n",
    "\n",
    "# Save the figure\n",
    "if outdir is not None:\n",
    "    sroi_str = ''\n",
    "    if do_sroi:\n",
    "        sroi_str = '_sroi{0:d}'.format(sroi)\n",
    "    filename = (outdir\n",
    "                / '_'.join(('histogram_metric' + sroi_str,\n",
    "                            start_date.strftime('%Y%m%d%H%M%S'),\n",
    "                            end_date.strftime('%Y%m%d%H%M%S')\n",
    "                            )))\n",
    "    filename = filename.with_suffix('.'+fig_type)\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='venn_diagram'></a>\n",
    "## Venn Diagram\n",
    "An alternative way of viewing the overlap between SITL, ABS, and GLS selections is with a Venn diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All segments\n",
    "#  - ABS segements that overlapped with at least one SITL segment\n",
    "#  - GLS segements that overlapped with at least one SITL segment\n",
    "#  - GLS segements that overlapped with at least one ABS segment\n",
    "#  - GLS segements that overlapped with at least one SITL-ABS segment\n",
    "sitl_abs_data = [segment\n",
    "                 for segment in abs_data\n",
    "                 if sel.selection_overlap(segment, sitl_data)['n_selections'] > 0]\n",
    "sitl_gls_data = [segment\n",
    "                 for segment in gls_data\n",
    "                 if sel.selection_overlap(segment, sitl_data)['n_selections'] > 0]\n",
    "abs_gls_data = [segment\n",
    "                for segment in gls_data\n",
    "                if sel.selection_overlap(segment, abs_data)['n_selections'] > 0]\n",
    "sitl_abs_gls_data = [segment\n",
    "                     for segment in gls_data\n",
    "                     if sel.selection_overlap(segment, sitl_abs_data)['n_selections'] > 0]\n",
    "\n",
    "# MP Segments\n",
    "#  - ABS segements that overlapped with at least one SITL MP segment\n",
    "#  - GLS segements that overlapped with at least one SITL MP segment\n",
    "#  - GLS segements that overlapped with at least one SITL MP-ABS segment\n",
    "sitl_mp_abs_data = [segment\n",
    "                    for segment in abs_data\n",
    "                    if sel.selection_overlap(segment, sitl_mp_data)['n_selections'] > 0]\n",
    "sitl_mp_gls_data = [segment\n",
    "                    for segment in gls_data\n",
    "                    if sel.selection_overlap(segment, sitl_mp_data)['n_selections'] > 0]\n",
    "sitl_mp_abs_gls_data = [segment\n",
    "                        for segment in gls_data\n",
    "                        if sel.selection_overlap(segment,\n",
    "                                                 sitl_mp_abs_data\n",
    "                                                 )['n_selections'] > 0\n",
    "                        ]\n",
    "\n",
    "# Numbers for Venn diagram\n",
    "n_sitl = len(sitl_data)\n",
    "n_abs = len(abs_data)\n",
    "n_sitl_abs = len(sitl_abs_data)\n",
    "n_gls = len(gls_data)\n",
    "n_sitl_gls = len(sitl_gls_data)\n",
    "n_abs_gls = len(abs_gls_data)\n",
    "n_sitl_abs_gls = len(sitl_abs_gls_data)\n",
    "\n",
    "# Numbers for Venn diagram\n",
    "n_sitl_mp = len(sitl_mp_data)\n",
    "n_sitl_mp_abs = len(sitl_mp_abs_data)\n",
    "n_sitl_mp_gls = len(sitl_mp_gls_data)\n",
    "n_sitl_mp_abs_gls = len(sitl_mp_abs_gls_data)\n",
    "\n",
    "# Setup the figure\n",
    "fig = plt.figure(figsize=(7, 4))\n",
    "\n",
    "# Venn Diagram: All Selections\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "venn3(subsets=[n_sitl, n_abs, n_sitl_abs,\n",
    "               n_gls, n_sitl_gls, n_abs_gls,\n",
    "               n_sitl_abs_gls\n",
    "               ],\n",
    "      set_labels=['SITL', 'ABS', 'GLS'],\n",
    "      alpha=0.4, ax=ax\n",
    "      )\n",
    "plt.title('All Selections')\n",
    "\n",
    "# Venn Diagram: MP Selections\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "venn3(subsets=[n_sitl_mp, n_abs, n_sitl_mp_abs,\n",
    "               n_gls, n_sitl_mp_gls, n_abs_gls,\n",
    "               n_sitl_mp_abs_gls\n",
    "               ],\n",
    "      set_labels=['SITL-MP', 'ABS', 'GLS'],\n",
    "      alpha=0.4, ax=ax\n",
    "      )\n",
    "plt.title('Magnetopause Selections')\n",
    "\n",
    "# Save the figure\n",
    "if outdir is not None:\n",
    "    sroi_str = ''\n",
    "    if do_sroi:\n",
    "        sroi_str = '_sroi{0:d}'.format(sroi)\n",
    "    filename = (outdir\n",
    "                / '_'.join(('venn_diagram' + sroi_str,\n",
    "                            start_date.strftime('%Y%m%d%H%M%S'),\n",
    "                            end_date.strftime('%Y%m%d%H%M%S')\n",
    "                            )))\n",
    "    filename = filename.with_suffix('.'+fig_type)\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='f1_score'></a>\n",
    "## Confusion Matrix, Precion, Recall, and F1 Score\n",
    "Assess the model by creating the confusion matrix and computing the precision, recall, and F1 score. To do this, we need to first determine all possible time stamps for which the STIL can make selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_time_stamps(start_time, end_time, sc='mms1', method='mdq'):\n",
    "    '''\n",
    "    Find all times available to the SITL for selection. The SITL\n",
    "    can make a selection whenever an MDQ is defined. MDQs are defined\n",
    "    in the ABS and SITL selection files as the `'timestamp'` field.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    start_time, end_time : `datetime.datetime`\n",
    "        Time interval in which to create time stamps\n",
    "    sc : str\n",
    "        Reference spacecraft for SROI boundaries. Used only if\n",
    "        `method='sroi'`\n",
    "    method : str\n",
    "        Method by which to create time stamps. Options are 'sroi'\n",
    "        and 'mdq'. Time stamps for the former are tied to the begin\n",
    "        and end times of each SROI and are spacecraft-specific. In\n",
    "        the latter case, time stamps are taken from MDQ values,\n",
    "        which are spacecraft independent.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    time_stamps : `np.array(dtype='int64')`\n",
    "        All times at which a SITL could have made a selection.\n",
    "    '''\n",
    "    if method == 'sroi':\n",
    "        # Create a time array for each sroi\n",
    "        orbit_0 = api.time_to_orbit(start_time, sc=sc)\n",
    "        orbit_1 = api.time_to_orbit(end_time, sc=sc)\n",
    "    \n",
    "        # Loop through the SROIs\n",
    "        time_stamps = np.empty(0, dtype='int64')\n",
    "        for orbit in range(orbit_0, orbit_1 + 1):\n",
    "            sroi = sdc.mission_events('sroi', orbit, orbit, sc=sc)\n",
    "            for tstart, tend in zip(sroi['tstart'], sroi['tend']):\n",
    "                # Convert SROI interval to TAI seconds\n",
    "                tai_start = api.datetime_to_tai(tstart)\n",
    "                tai_stop = api.datetime_to_tai(tend)\n",
    "                tai_start = tai_start - (tai_start % t_delta)\n",
    "                tai_stop = tai_stop - (tai_stop % t_delta)\n",
    "    \n",
    "                # Create a pandas dataframe with tai_sroi as the index\n",
    "                time_stamps = np.append(time_stamps,\n",
    "                                        np.arange(tai_start,\n",
    "                                                  tai_stop,\n",
    "                                                  t_delta)\n",
    "                                        )\n",
    "\n",
    "    elif method == 'mdq':\n",
    "        # This is how I would retrieve all possible\n",
    "        # times that could be selected by the SITL. I would (1) ignore ROI\n",
    "        # information provided by SDC, (2) retrieve ABS or SITL sav files,\n",
    "        # and (3) look for the TIMESTAMPS tag. These timestamps define the\n",
    "        # start time of every \"cycle\" (It is called \"buffer\" if selected by\n",
    "        # the SITL). So, 10.0 needs to be added to the end time to get the\n",
    "        # end time of the timestamps. I would repeat these commands for all\n",
    "        # ABS files. Note that, after the dynamic SITL window system is\n",
    "        # introduced, a time range in one ABS file can be overlapped with a\n",
    "        # time range in another ABS file. \n",
    "    \n",
    "        # Get all ABS selection data within the time interval\n",
    "        abs_data = api.burst_selections('abs', start_time, end_time)\n",
    "    \n",
    "        # Multiple duplicate/overlapping ABS files can be submitted per orbit/roi\n",
    "        # Also, since files only contain start time, some data can be outside\n",
    "        # the given time interval.\n",
    "        time_stamps = np.unique(abs_data['timestamps'])\n",
    "        \n",
    "        # Trim time stamps to time interval\n",
    "        tai_tstart = api.datetime_to_tai(start_time)\n",
    "        tai_tend = api.datetime_to_tai(end_time)\n",
    "        time_stamps = time_stamps[((time_stamps >= tai_tstart)\n",
    "                                   & (time_stamps <= tai_tend))\n",
    "                                   ]\n",
    "\n",
    "    return time_stamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the SITL selections as the ground truth to compute the model scores for the ABS and GLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all possible time stamps\n",
    "t = selection_time_stamps(start_date, end_date, method='mdq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time cadence at which the SITL can make selections\n",
    "t_delta = seconds=10\n",
    "\n",
    "# Selections are made up of 10-second duration burst buffers. Burst\n",
    "# buffers begin at multiples of 10-seconds in TAI time. A selection\n",
    "# of duration 60 seconds contains 6 burst buffers.\n",
    "\n",
    "# Time stamps for 'sitl+back' are from the begin time of the first\n",
    "# burst buffer to the begin time of the last burst buffer, so that\n",
    "# adjacent selections are separated by 10 seconds.\n",
    "\n",
    "# Time stamps for all other selections are from the begin time of\n",
    "# the first burst buffer to the end time of the last burst buffer,\n",
    "# so that adjacent selections are separated by 0 seconds.\n",
    "\n",
    "# Selections are only possible in the SROI when MMS is in fast\n",
    "# survey mode. Selections occur on multiples of 10-seconds in TAI\n",
    "# time. To build up the time stamps, take the begin time of an\n",
    "# SROI and round down to the nearest 10s TAI time, take the end\n",
    "# time of the same SROI and round up to the nearest 10s TAI time,\n",
    "# then fill between at a cadence of 10 seconds.\n",
    "\n",
    "# Create a pandas DataFrame to make indexing by timestamps simple\n",
    "npts = len(t)\n",
    "tai_sroi = pd.Index(t)\n",
    "df = pd.DataFrame(index=tai_sroi)\n",
    "df['sitl'] = np.zeros(npts, dtype='bool')\n",
    "df['sitl_mp'] = np.zeros(npts, dtype='bool')\n",
    "df['abs'] = np.zeros(npts, dtype='bool')\n",
    "df['gls'] = np.zeros(npts, dtype='bool')\n",
    "\n",
    "# Python array slicing is exclusive [start, stop). Time stamps `t` are\n",
    "# the begin time of each \"cycle\" that can be selected by the sitl.\n",
    "\n",
    "# 'sitl' selection begin at the begin time of a cycle and extend to the\n",
    "# end time of the last cycle. This end time is excluded automatically by\n",
    "# Python slicing.\n",
    "\n",
    "# 'abs' and 'gls' selections, however, extend from the begin time of the\n",
    "# first cycle to the begin time of the last cycle. To ensure that the last\n",
    "# cycle is included in the results, extend each segment to the end of the\n",
    "# cycle.\n",
    "for segment in sitl_data:\n",
    "    df.loc[segment.taistarttime:segment.taiendtime, 'sitl'] = True\n",
    "for segment in sitl_mp_data:\n",
    "    df.loc[segment.taistarttime:segment.taiendtime, 'sitl_mp'] = True\n",
    "for segment in abs_data:\n",
    "    df.loc[segment.taistarttime:segment.taiendtime + t_delta, 'abs'] = True\n",
    "for segment in gls_data:\n",
    "    df.loc[segment.taistarttime:segment.taiendtime + t_delta, 'gls'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to calculate precision, recall, and F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(true_positive, false_negative):\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "def precision(true_positive, false_positive):\n",
    "    return true_positive / (true_positive + false_positive)\n",
    "def f1_score(prec, rec):\n",
    "    return 2 * prec * rec / (prec + rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claculate model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame of results\n",
    "score_df = pd.DataFrame(columns=['true_positive', 'false_positive', 'true_negative', 'false_negative',\n",
    "                                 'recall', 'precision', 'f1_score'],\n",
    "                        index=['GLS_ALL', 'GLS_MP', 'ABS'])\n",
    "\n",
    "# Confusion matrices\n",
    "score_df['true_positive']['GLS_ALL'] = (df.sitl & df.gls).sum()\n",
    "score_df['false_positive']['GLS_ALL'] = (~df.sitl & df.gls).sum()\n",
    "score_df['true_negative']['GLS_ALL'] = (~df.sitl & ~df.gls).sum()\n",
    "score_df['false_negative']['GLS_ALL'] = (df.sitl & ~df.gls).sum()\n",
    "\n",
    "score_df['true_positive']['GLS_MP'] = (df.sitl_mp & df.gls).sum()\n",
    "score_df['false_positive']['GLS_MP'] = (~df.sitl_mp & df.gls).sum()\n",
    "score_df['true_negative']['GLS_MP'] = (~df.sitl_mp & ~df.gls).sum()\n",
    "score_df['false_negative']['GLS_MP'] = (df.sitl_mp & ~df.gls).sum()\n",
    "\n",
    "score_df['true_positive']['ABS'] = (df.sitl & df['abs']).sum()\n",
    "score_df['false_positive']['ABS'] = (~df.sitl & df['abs']).sum()\n",
    "score_df['true_negative']['ABS'] = (~df.sitl & ~df['abs']).sum()\n",
    "score_df['false_negative']['ABS'] = (df.sitl & ~df['abs']).sum()\n",
    "\n",
    "# Metrics\n",
    "score_df['precision'] = precision(score_df['true_positive'], score_df['false_positive'])\n",
    "score_df['recall'] = recall(score_df['true_positive'], score_df['false_negative'])\n",
    "score_df['f1_score'] = f1_score(score_df['precision'], score_df['recall'])\n",
    "\n",
    "print(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write results to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if outdir is not None:\n",
    "    sroi_str = ''\n",
    "    if do_sroi:\n",
    "        sroi_str = '_sroi{0:d}'.format(sroi)\n",
    "    filename = (outdir\n",
    "                / '_'.join(('performance_metrics' + sroi_str,\n",
    "                            start_date.strftime('%Y%m%d%H%M%S'),\n",
    "                            end_date.strftime('%Y%m%d%H%M%S')\n",
    "                            )))\n",
    "    filename = filename.with_suffix('.csv')\n",
    "    \n",
    "    # Write\n",
    "    score_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='confusion_matrix'></a>\n",
    "## Plot Confusion Matrix\n",
    "This function was adapted from [Kaggle](https://www.kaggle.com/grfiv4/plot-a-confusion-matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          ax=ax,\n",
    "                          figsize=(8,6),\n",
    "                          cmap=None,\n",
    "                          log=False,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix'):\n",
    "    \"\"\"\n",
    "    Given a confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "    \n",
    "    ax:           Axes in which to draw the confusion matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "    \n",
    "    log:          If True, the colorbar displays the log of the matix\n",
    "                  If False, the colorbar is scaled linearly\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111)\n",
    "    \n",
    "    if log:\n",
    "        img = ax.imshow(np.log10(cm), interpolation='nearest', cmap=cmap)\n",
    "        cb_title = '$\\mathrm{Log_{10}(N)}$'\n",
    "    else:\n",
    "        img = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        cb_title = 'N'\n",
    "    ax.set_title(title)\n",
    "    cbar = plt.colorbar(img, ax=ax, shrink=0.6)\n",
    "    cbar.ax.set_ylabel(cb_title)\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        ax.set_xticks(tick_marks)\n",
    "        ax.set_xticklabels(target_names, rotation=0)\n",
    "        ax.set_yticks(tick_marks)\n",
    "        ax.set_yticklabels(target_names, rotation=90, verticalalignment='center')\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cm.shape == (2,2):\n",
    "        bb = [['TP', 'FN'], ['FP', 'TN']]\n",
    "    else:\n",
    "        bb = [['', ''], ['', '']]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            ax.text(j, i, \"{0:0.4f}\\n{1}\".format(cm[i, j], bb[i][j]),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    verticalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            ax.text(j, i, \"{0:,}\\n{1}\".format(cm[i, j], bb[i][j]),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    verticalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_gls_all = np.array([[score_df['true_positive']['GLS_ALL'], score_df['false_negative']['GLS_ALL']],\n",
    "                       [score_df['false_positive']['GLS_ALL'], score_df['true_negative']['GLS_ALL']]])\n",
    "cm_gls_mp = np.array([[score_df['true_positive']['GLS_MP'], score_df['false_negative']['GLS_MP']],\n",
    "                      [score_df['false_positive']['GLS_MP'], score_df['true_negative']['GLS_MP']]])\n",
    "cm_abs = np.array([[score_df['true_positive']['ABS'], score_df['false_negative']['ABS']],\n",
    "                   [score_df['false_positive']['ABS'], score_df['true_negative']['ABS']]])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(8.5,2.8))\n",
    "\n",
    "plot_confusion_matrix(cm_gls_all, ax=axes[0], log=True, normalize=False, target_names=['Positive', 'Negative'])\n",
    "axes[0].set_title('')\n",
    "axes[0].set_xlabel('GLS')\n",
    "axes[0].set_ylabel('SITL (ALL)')\n",
    "\n",
    "plot_confusion_matrix(cm_gls_mp, ax=axes[1], log=True, normalize=False, target_names=['Positive', 'Negative'])\n",
    "axes[1].set_title('Point-wise Confusion Matrices')\n",
    "axes[1].set_xlabel('GLS')\n",
    "axes[1].set_ylabel('SITL (MP)')\n",
    "\n",
    "plot_confusion_matrix(cm_abs, ax=axes[2], log=True, normalize=False, target_names=['Positive', 'Negative'])\n",
    "axes[2].set_title('')\n",
    "axes[2].set_xlabel('ABS')\n",
    "axes[2].set_ylabel('SITL (ALL)')\n",
    "\n",
    "# Save the figure\n",
    "if outdir is not None:\n",
    "    sroi_str = ''\n",
    "    if do_sroi:\n",
    "        sroi_str = '_sroi{0:d}'.format(sroi)\n",
    "    filename = (outdir\n",
    "                / '_'.join(('confusion_matrices' + sroi_str,\n",
    "                            start_date.strftime('%Y%m%d%H%M%S'),\n",
    "                            end_date.strftime('%Y%m%d%H%M%S')\n",
    "                            )))\n",
    "    filename = filename.with_suffix('.'+fig_type)\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
